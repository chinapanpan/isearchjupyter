{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b72e52e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.28.3)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.31.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.3->boto3) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.3->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.3->boto3) (1.16.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.172.0)\n",
      "Collecting sagemaker\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c7/ec/74e608c9e3458c16464265c38018f4e26b4232d5a46674a277af15bd56ac/sagemaker-2.173.0.tar.gz (854 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m854.4/854.4 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.28.3)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.22.3)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.5.2)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.6.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (65.6.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2022.7)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.3->boto3<2.0,>=1.26.131->sagemaker) (1.26.8)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.173.0-py2.py3-none-any.whl size=1163282 sha256=8fbe4b0dd88e70c2462c7595a5a3487f2bcb5382c783b5969cc0176fbb9d3eda\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/1e/17/62/f26f1c76dc9f61074757e03f3123841ac209dba14ba38e66ae\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.172.0\n",
      "    Uninstalling sagemaker-2.172.0:\n",
      "      Successfully uninstalled sagemaker-2.172.0\n",
      "Successfully installed sagemaker-2.173.0\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: python_docx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.8.11)\n",
      "Requirement already satisfied: lxml>=2.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python_docx) (4.9.3)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.0.232)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.22.3)\n",
      "Requirement already satisfied: langsmith<0.0.6,>=0.0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (0.0.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.4.46)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (8.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pypdf in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.12.1)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: docx2txt in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "!pip install --upgrade boto3 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install --upgrade sagemaker -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install python_docx -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install langchain -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install pypdf -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install docx2txt -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca88125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from chinese_text_splitter import ChineseTextSplitter\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import requests\n",
    "\n",
    "nltk.download('punkt')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab46c74-4ef9-48b0-b4ec-8289e59ae840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from chinese_text_splitter import ChineseTextSplitter\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c462bf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7e860b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please put data in this folder--> docs/\n"
     ]
    }
   ],
   "source": [
    "# The name of index\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "#index_name = sm_client.get_secret_value(SecretId='opensearch-index-name')['SecretString']\n",
    "#data= json.loads(index_name)\n",
    "#index_name = data.get('index')\n",
    "#print('pre-defined index name in deployment/cdk.json-->',index_name)\n",
    "index_name = 'test'\n",
    "\n",
    "# Language, 'chinese' or 'english'\n",
    "language = 'chinese'\n",
    "\n",
    "# The name of embbeding model endpoint, usually you can keep it as default\n",
    "eb_endpoint = 'huggingface-inference-eb'\n",
    "\n",
    "# Ebbeding vector dimension, usually you can keep it as default\n",
    "v_dimension = 768\n",
    "\n",
    "# Docs file folder to be processed and ingested\n",
    "folder_path = 'docs/'\n",
    "print('Please put data in this folder-->',folder_path)\n",
    "\n",
    "# Paragraph size / Chunck size\n",
    "chunck_size = 200\n",
    "\n",
    "# The imported data of the same index_name, usually you can keep it as 0 if you are creating a new index\n",
    "before_import = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c82381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 85 85\n",
      " import 9 out of 9 finished file 1 out of 1 finished\n"
     ]
    }
   ],
   "source": [
    "hfp = sagemaker.huggingface.model.HuggingFacePredictor(eb_endpoint)\n",
    "\n",
    "#===================Function Definition=================\n",
    "\n",
    "def load_file(filepath,language):\n",
    "    \n",
    "    if filepath.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".pptx\"):\n",
    "        loader = UnstructuredPowerPointLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".csv\"):\n",
    "        loader = CSVLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".txt\"):\n",
    "        loader = TextLoader(filepath)\n",
    "    else:\n",
    "        loader = TextLoader(filepath)\n",
    "\n",
    "    if language == \"chinese\":\n",
    "        textsplitter = ChineseTextSplitter()\n",
    "    elif language == \"english\":\n",
    "        textsplitter = NLTKTextSplitter(chunk_size=chunck_size, chunk_overlap=10)\n",
    "\n",
    "    docs = loader.load_and_split(textsplitter)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def get_title(path):\n",
    "    try:\n",
    "        title = os.path.split(os.path.splitext(path)[0])[1].replace('——', '-').split('-')[1]\n",
    "    except:\n",
    "        title = os.path.split(os.path.splitext(path)[0])[1]\n",
    "    return title\n",
    "\n",
    "def read_doc(path, chunck_size = chunck_size):\n",
    "    doc = load_file(path, language)\n",
    "    title = get_title(path)\n",
    "    titles = []\n",
    "    paragraphs = []\n",
    "    sentences = []\n",
    "    para = ''\n",
    "    con = 0\n",
    "    for d in doc:\n",
    "#         print('*********')\n",
    "        con += 1\n",
    "        titles.append(title)\n",
    "        sentences.append(d.page_content)\n",
    "        para += d.page_content\n",
    "        if len(para) >= chunck_size:\n",
    "            paragraphs += [para for _ in range(con)]\n",
    "            para = ''\n",
    "            con = 0\n",
    "    paragraphs += [para for _ in range(con)]\n",
    "    print(len(titles), len(sentences),len(paragraphs))\n",
    "    df = pd.DataFrame({'title':titles, 'paragraph':paragraphs, 'sentence':sentences})\n",
    "    return df\n",
    "\n",
    "def get_vector(q):\n",
    "    try:\n",
    "        vector = hfp.predict({'inputs':[q]})[0][0][0]\n",
    "        return vector\n",
    "    except:\n",
    "        return [-1000 for _ in range(v_dimension)]\n",
    "    return hfp.predict({'inputs':[q]})[0][0][0]\n",
    "\n",
    "def embbeding(df):\n",
    "    df['title_vector'] = ''\n",
    "    df['sentence_vector'] = ''\n",
    "    title_vector = str(get_vector(df.iloc[0, 0]))\n",
    "    for i in range(len(df)):\n",
    "#         df.iloc[i, 5] = title_vector\n",
    "        df.iloc[i, 3] = str(get_vector(df.iloc[i, 2]))\n",
    "        print('\\r embbeding %i out of %i finished'%(i, len(df)), end='')\n",
    "    return df\n",
    "\n",
    "# ==============OpenSearch Related=====================\n",
    "# retrieve secret manager value by key using boto3\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "# sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n",
    "# service = 'es'\n",
    "# credentials = boto3.Session().get_credentials()\n",
    "awsauth = (username, password)\n",
    "url = host+'_bulk'\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "payloads = {\n",
    "\"settings\": { \"index\": {\n",
    "\"knn\": True,\n",
    "\"knn.algo_param.ef_search\": 100 }\n",
    "}, \"mappings\": {\n",
    "\"properties\": { \n",
    "  \"title_vector\": {\n",
    "\"type\": \"knn_vector\", \"dimension\": v_dimension, \"method\": {\n",
    "\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"nmslib\", \"parameters\": {\n",
    "\"ef_construction\": 256,\n",
    "\"m\": 128 }\n",
    "} },\n",
    "\"sentence_vector\": {\n",
    "\"type\": \"knn_vector\", \"dimension\": v_dimension, \"method\": {\n",
    "\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"nmslib\", \"parameters\": {\n",
    "\"ef_construction\": 256,\n",
    "\"m\": 128 }\n",
    "} },\n",
    "\"title\": { \"type\": \"text\"}, \n",
    "\"sentence\": {\"type\": \"text\" }, \n",
    "\"paragraph\": {\"type\": \"text\" }, \n",
    "\"sentence_id\": {\"type\": \"text\" }, \n",
    "\"paragraph_id\": {\"type\": \"text\" }\n",
    "} }\n",
    "}\n",
    "\n",
    "# Create Index\n",
    "r = requests.delete(host+index_name, auth=awsauth, headers=headers, json={})\n",
    "r = requests.put(host+index_name, auth=awsauth, headers=headers, json=payloads)\n",
    "\n",
    "def import_data(df, id_start=0, before_import=0):\n",
    "    payloads = ''\n",
    "    for i in range(id_start, len(df)+id_start):\n",
    "        first = json.dumps({ \"index\": { \"_index\": index_name, \"_id\": str(i+before_import) } }, ensure_ascii=False) + \"\\n\"\n",
    "        second = json.dumps({\"title\": str(df.iloc[i-id_start, 0]), \n",
    "                     \"paragraph\": str(df.iloc[i-id_start, 1]), \n",
    "                     \"sentence\": str(df.iloc[i-id_start, 2]), \n",
    "                     \"sentence_vector\": json.loads(df.iloc[i-id_start, 3])},\n",
    "                   ensure_ascii=False) + \"\\n\"\n",
    "        payloads += first + second\n",
    "    # print(payloads)\n",
    "    r = requests.post(url, auth=awsauth, headers=headers, data=payloads.encode()) # requests.get, post, and delete have similar syntax\n",
    "#     print(r.text)\n",
    "\n",
    "#==============Main Preprocess Data and Import===============\n",
    "\n",
    "slice = 10\n",
    "names = os.listdir(folder_path)\n",
    "# before_import = 0\n",
    "failed_files = []\n",
    "for j in range(len(names)):\n",
    "    name = names[j]\n",
    "#     if os.path.splitext(name)[1] not in ['.doc','.docx']:continue\n",
    "    try:\n",
    "        df = read_doc(os.path.join(folder_path, name))\n",
    "        df = embbeding(df)\n",
    "        for i in range(len(df)//slice+1):\n",
    "            import_data(df[slice*i:slice*(i+1)], slice*i, before_import)\n",
    "            print('\\r import %i out of %i finished'%(i+1, len(df)//slice+1), end='')\n",
    "        before_import += len(df)\n",
    "        print(' file %i out of %i finished'%(j+1, len(names)//slice+1))\n",
    "    except Exception as ex:\n",
    "        # traceback.print_exc(file=sys.stdout)\n",
    "        failed_files.append(name)\n",
    "        print(f\"=================Exception================={ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8e622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ee97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
