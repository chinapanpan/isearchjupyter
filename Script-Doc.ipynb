{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542f8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0c2e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install python_docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b11e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sagemaker Endpoint Deploy\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'shibing624/text2vec-base-chinese',\n",
    "\t'HF_TASK':'feature-extraction'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.17.0',\n",
    "\tpytorch_version='1.10.2',\n",
    "\tpy_version='py38',\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tendpoint_name='huggingface-inference-text2vec-base-chinese-v1',\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\t# instance_type='ml.m5.xlarge' # ec2 instance type\n",
    "\tinstance_type='ml.p3.2xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633841bc-df6d-4b02-a45c-161fe65f377b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference testing\n",
    "import time\n",
    "\n",
    "hfp = sagemaker.huggingface.model.HuggingFacePredictor('huggingface-inference-text2vec-base-chinese-v1')\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(10):\n",
    "    hfp.predict({'inputs':''.join(['打印' for _ in range(100)])})[0][0][0]\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c23b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preprocess Data\n",
    "import os\n",
    "import docx\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import json\n",
    "import boto3\n",
    "import requests\n",
    "\n",
    "def is_all_black(s):\n",
    "    for si in s:\n",
    "        if si != ' ':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def read_doc(path):\n",
    "    title = get_title(path)\n",
    "    titles = []\n",
    "    paragraphs = []\n",
    "    sentences = []\n",
    "    paragraphs_id = []\n",
    "    sentences_id = []\n",
    "    \n",
    "    document = Document(path)  # 读入文件\n",
    "    for i in range(len(document.paragraphs)):\n",
    "        p0 = document.paragraphs[i].text\n",
    "        p = document.paragraphs[i].text.replace('. ', '。')\n",
    "        if p != '':\n",
    "            ss = p.split('。')\n",
    "            for j in range(len(ss)):\n",
    "                if ss[j] != '' and is_all_black(ss[j])==False:\n",
    "                    titles.append(title)\n",
    "                    paragraphs.append(p0)\n",
    "                    sentences.append(ss[j])\n",
    "                    paragraphs_id.append(i)\n",
    "                    sentences_id.append(j)\n",
    "    df = pd.DataFrame({'title':titles, 'paragraph':paragraphs, 'sentence':sentences,\n",
    "                      'paragraph_id':paragraphs_id, 'sentence_id':sentences_id})          \n",
    "    return df\n",
    "\n",
    "def get_title(path):\n",
    "    try:\n",
    "        title = os.path.split(os.path.splitext(path)[0])[1].replace('——', '-').split('-')[1]\n",
    "    except:\n",
    "        title = os.path.split(os.path.splitext(path)[0])[1]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f410c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hfp = sagemaker.huggingface.model.HuggingFacePredictor('huggingface-inference-text2vec-base-chinese-v1')\n",
    "\n",
    "def get_vector(q):\n",
    "    if len(q) > 400:\n",
    "        return [-1000 for _ in range(768)]\n",
    "    return hfp.predict({'inputs':[q]})[0][0][0]\n",
    "\n",
    "def embbeding(df):\n",
    "    df['title_vector'] = ''\n",
    "    df['sentence_vector'] = ''\n",
    "    title_vector = str(get_vector(df.iloc[0, 0]))\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i, 5] = title_vector\n",
    "        df.iloc[i, 6] = str(get_vector(df.iloc[i, 2]))\n",
    "        print('\\r embbeding %i out of %i finished'%(i, len(df)), end='')\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9c2c224",
   "metadata": {},
   "source": [
    "### Input your customerized index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32458c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import data to OpenSearch\n",
    "import boto3\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "host_url = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "urldata= json.loads(host_url)\n",
    "host = urldata.get('host') # cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "region = os.getenv('AWS_REGION', '') # e.g. cn-north-1\n",
    "index_name = \"docs\"     # pls customized your index name, default is 'docs'\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n",
    "\n",
    "service = 'es'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "\n",
    "\n",
    "awsauth = (username, password)\n",
    "\n",
    "\n",
    "url = host+'_bulk'\n",
    "\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "def import_data(df, id_start=0, before_import=0):\n",
    "    payloads = ''\n",
    "    for i in range(id_start, len(df)+id_start):\n",
    "        first = json.dumps({ \"index\": { \"_index\": index_name, \"_id\": str(i+before_import) } }, ensure_ascii=False) + \"\\n\"\n",
    "        second = json.dumps({\"title\": str(df.iloc[i-id_start, 0]), \n",
    "                     \"paragraph\": str(df.iloc[i-id_start, 1]), \n",
    "                     \"sentence\": str(df.iloc[i-id_start, 2]), \n",
    "                     \"paragraph_id\": str(df.iloc[i-id_start, 3]), \n",
    "                     \"sentence_id\": str(df.iloc[i-id_start, 4]), \n",
    "                     \"title_vector\": json.loads(df.iloc[i-id_start, 5]),\n",
    "                     \"sentence_vector\": json.loads(df.iloc[i-id_start, 6])},\n",
    "                   ensure_ascii=False) + \"\\n\"\n",
    "        payloads += first + second\n",
    "    # print(payloads)\n",
    "    r = requests.post(url, auth=awsauth, headers=headers, data=payloads.encode()) # requests.get, post, and delete have similar syntax\n",
    "#     print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "569c2f76",
   "metadata": {},
   "source": [
    "### Input your customized folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f412d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Preprocess Data and Import\n",
    "\n",
    "hfp = sagemaker.huggingface.model.HuggingFacePredictor('huggingface-inference-text2vec-base-chinese-v1')\n",
    "\n",
    "folder_path = ''\n",
    "\n",
    "slice = 10\n",
    "\n",
    "names = os.listdir(folder_path)\n",
    "before_import = 0\n",
    "for j in range(len(names)):\n",
    "    name = names[j]\n",
    "    df = read_doc(os.path.join(folder_path, name))\n",
    "    df = embbeding(df)\n",
    "    for i in range(len(df)//slice+1):\n",
    "        import_data(df[slice*i:slice*(i+1)], slice*i, before_import)\n",
    "        print('\\r import %i out of %i finished'%(i, len(df)//slice+1), end='')\n",
    "    before_import += len(df)\n",
    "    print(' file %i out of %i finished'%(j, len(names)//slice+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dynamo DB\n",
    "client = boto3.client('dynamodb', region_name='us-west-2')\n",
    "\n",
    "try:\n",
    "    resp = client.create_table(\n",
    "        TableName=\"FeedbackRecordsSEWCFAQ\",\n",
    "        # Declare your Primary Key in the KeySchema argument\n",
    "        KeySchema=[\n",
    "            {\n",
    "                \"AttributeName\": \"SearchInputs\",\n",
    "                \"KeyType\": \"HASH\"\n",
    "            },\n",
    "            {\n",
    "                \"AttributeName\": \"_id\",\n",
    "                \"KeyType\": \"RANGE\"\n",
    "            }\n",
    "        ],\n",
    "        # Any attributes used in KeySchema or Indexes must be declared in AttributeDefinitions\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                \"AttributeName\": \"SearchInputs\",\n",
    "                \"AttributeType\": \"S\"\n",
    "            },\n",
    "            {\n",
    "                \"AttributeName\": \"_id\",\n",
    "                \"AttributeType\": \"S\"\n",
    "            }\n",
    "        ],\n",
    "        # ProvisionedThroughput controls the amount of data you can read or write to DynamoDB per second.\n",
    "        # You can control read and write capacity independently.\n",
    "        ProvisionedThroughput={\n",
    "            \"ReadCapacityUnits\": 50,\n",
    "            \"WriteCapacityUnits\": 50\n",
    "        }\n",
    "    )\n",
    "    print(\"Table created successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating table:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc59b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
