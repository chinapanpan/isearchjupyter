{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b72e52e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.28.78)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.78 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.31.78)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.78->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.78->boto3) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.78->boto3) (1.16.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.196.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.28.78)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.24.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.23.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.18.4)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.9.1)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.78 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.78)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.16.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.30.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.78->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: python_docx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python_docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python_docx) (4.7.1)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.330)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (0.0.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.9)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: pypdf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.17.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: docx2txt in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.8)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Collecting nltk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (1.3.1)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.10.3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "!pip install --upgrade boto3 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install --upgrade sagemaker -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install python_docx -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install langchain -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install pypdf -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install docx2txt -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install nltk -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca88125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from chinese_text_splitter import ChineseTextSplitter\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import requests\n",
    "\n",
    "nltk.download('punkt')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ab46c74-4ef9-48b0-b4ec-8289e59ae840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from chinese_text_splitter import ChineseTextSplitter\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c462bf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c7e860b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please put data in this folder--> docs/\n"
     ]
    }
   ],
   "source": [
    "# The name of index\n",
    "#sm_client = boto3.client('secretsmanager')\n",
    "#index_name = sm_client.get_secret_value(SecretId='opensearch-index-name')['SecretString']\n",
    "#data= json.loads(index_name)\n",
    "#index_name = data.get('index')\n",
    "#print('pre-defined index name in deployment/cdk.json-->',index_name)\n",
    "index_name = 'test'\n",
    "\n",
    "# Language, 'chinese' or 'english'\n",
    "language = 'chinese'\n",
    "\n",
    "# The name of embbeding model endpoint, usually you can keep it as default\n",
    "eb_endpoint = 'huggingface-inference-eb'\n",
    "\n",
    "# Ebbeding vector dimension, usually you can keep it as default\n",
    "v_dimension = 768\n",
    "\n",
    "# Docs file folder to be processed and ingested\n",
    "folder_path = 'docs/'\n",
    "print('Please put data in this folder-->',folder_path)\n",
    "\n",
    "# Paragraph size / Chunck size\n",
    "chunck_size = 400\n",
    "\n",
    "# The imported data of the same index_name, usually you can keep it as 0 if you are creating a new index\n",
    "before_import = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f607b27-bfdb-476e-833b-c73d29bc2e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: search-smartsearch-bdhdkttjx3nshmf2flseozrqly.cn-north-1.es.amazonaws.com.cn\n",
      "region: cn-north-1\n"
     ]
    }
   ],
   "source": [
    "#删除索引\n",
    "import requests\n",
    "import boto3\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "host = host[8:-1]\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "print('host:',host)\n",
    "print('region:',region)\n",
    "\n",
    "# retrieve secret manager value by key using boto3                                             \n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n",
    "\n",
    "index =  \"test\"\n",
    "awsauth = (username, password)\n",
    "url = host+'_bulk'\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "r = requests.delete(\"https://\"+host+\"/\"+index, auth=awsauth, headers=headers, json={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06c82381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "9 9 9\n",
      " import 1 out of 1 finished file 1 out of 1 finished\n",
      "=================Exception=================Error loading docs/.ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "hfp = sagemaker.huggingface.model.HuggingFacePredictor('huggingface-inference-eb')\n",
    "\n",
    "#===================Function Definition=================\n",
    "\n",
    "def load_file(filepath,language):\n",
    "    \n",
    "    if filepath.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".pptx\"):\n",
    "        loader = UnstructuredPowerPointLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".csv\"):\n",
    "        loader = CSVLoader(filepath)\n",
    "    elif filepath.lower().endswith(\".txt\"):\n",
    "        loader = TextLoader(filepath)\n",
    "    else:\n",
    "        loader = TextLoader(filepath)\n",
    "\n",
    "    if language == \"chinese\":\n",
    "        textsplitter = ChineseTextSplitter()\n",
    "    elif language == \"english\":\n",
    "        textsplitter = NLTKTextSplitter(chunk_size=chunck_size, chunk_overlap=10)\n",
    "\n",
    "    docs = loader.load_and_split(textsplitter)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def get_title(path):\n",
    "    try:\n",
    "        title = os.path.split(os.path.splitext(path)[0])[1].replace('——', '-').split('-')[1]\n",
    "    except:\n",
    "        title = os.path.split(os.path.splitext(path)[0])[1]\n",
    "    return title\n",
    "\n",
    "def read_doc(path, chunck_size = chunck_size):\n",
    "    doc = load_file(path, language)\n",
    "    title = get_title(path)\n",
    "    titles = []\n",
    "    paragraphs = []\n",
    "    sentences = []\n",
    "    para = ''\n",
    "    con = 0\n",
    "    for d in doc:\n",
    "#         print('*********')\n",
    "        con += 1\n",
    "        titles.append(title)\n",
    "        sentences.append(d.page_content)\n",
    "        para += d.page_content\n",
    "        \n",
    "        if len(para) >= chunck_size:\n",
    "            \n",
    "            paragraphs += [para for _ in range(con)]\n",
    "            para = ''\n",
    "            con = 0\n",
    "    paragraphs += [para for _ in range(con)]\n",
    "    print(len(titles), len(sentences),len(paragraphs))\n",
    "    df = pd.DataFrame({'title':titles, 'paragraph':paragraphs, 'sentence':sentences})\n",
    "    return df\n",
    "\n",
    "def get_vector(q):\n",
    "    try:\n",
    "        result=hfp.predict({'inputs':[q]})\n",
    "        if \"sentence_embeddings\" in result:                                   \n",
    "            return result[\"sentence_embeddings\"][0][0]\n",
    "        else:\n",
    "            return result[0][0][0]\n",
    "        \n",
    "        #vector = hfp.predict({'inputs':[q]})[0][0][0]\n",
    "        return vector\n",
    "    except:\n",
    "        return [-1000 for _ in range(v_dimension)]\n",
    "    return hfp.predict({'inputs':[q]})[0][0][0]\n",
    "\n",
    "def embbeding(df):\n",
    "    df['title_vector'] = ''\n",
    "    df['sentence_vector'] = ''\n",
    "    title_vector = str(get_vector(df.iloc[0, 0]))\n",
    "    for i in range(len(df)):\n",
    "#         df.iloc[i, 5] = title_vector\n",
    "        df.iloc[i, 3] = str(get_vector(df.iloc[i, 2]))\n",
    "        print('\\r embbeding %i out of %i finished'%(i, len(df)), end='')\n",
    "    return df\n",
    "\n",
    "# ==============OpenSearch Related=====================\n",
    "# retrieve secret manager value by key using boto3\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "# sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n",
    "# service = 'es'\n",
    "# credentials = boto3.Session().get_credentials()\n",
    "awsauth = (username, password)\n",
    "url = host+'_bulk'\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "payloads = {\n",
    "\"settings\": { \"index\": {\n",
    "\"knn\": True,\n",
    "\"knn.algo_param.ef_search\": 100 }\n",
    "}, \"mappings\": {\n",
    "\"properties\": { \n",
    "  \"title_vector\": {\n",
    "\"type\": \"knn_vector\", \"dimension\": v_dimension, \"method\": {\n",
    "\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"nmslib\", \"parameters\": {\n",
    "\"ef_construction\": 256,\n",
    "\"m\": 128 }\n",
    "} },\n",
    "\"sentence_vector\": {\n",
    "\"type\": \"knn_vector\", \"dimension\": v_dimension, \"method\": {\n",
    "\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"nmslib\", \"parameters\": {\n",
    "\"ef_construction\": 256,\n",
    "\"m\": 128 }\n",
    "} },\n",
    "\"title\": { \"type\": \"text\"}, \n",
    "\"sentence\": {\"type\": \"text\" }, \n",
    "\"paragraph\": {\"type\": \"text\" }, \n",
    "\"sentence_id\": {\"type\": \"text\" }, \n",
    "\"paragraph_id\": {\"type\": \"text\" }\n",
    "} }\n",
    "}\n",
    "\n",
    "# Create Index\n",
    "r = requests.delete(host+index_name, auth=awsauth, headers=headers, json={})\n",
    "r = requests.put(host+index_name, auth=awsauth, headers=headers, json=payloads)\n",
    "\n",
    "def import_data(df, id_start=0, before_import=0):\n",
    "    payloads = ''\n",
    "    for i in range(id_start, len(df)+id_start):\n",
    "        first = json.dumps({ \"index\": { \"_index\": index_name, \"_id\": str(i+before_import) } }, ensure_ascii=False) + \"\\n\"\n",
    "        second = json.dumps({\"title\": str(df.iloc[i-id_start, 0]), \n",
    "                     \"paragraph\": str(df.iloc[i-id_start, 1]), \n",
    "                     \"sentence\": str(df.iloc[i-id_start, 2]), \n",
    "                     \"sentence_vector\": json.loads(df.iloc[i-id_start, 3])},\n",
    "                   ensure_ascii=False) + \"\\n\"\n",
    "        payloads += first + second\n",
    "    # print(payloads)\n",
    "    r = requests.post(url, auth=awsauth, headers=headers, data=payloads.encode()) # requests.get, post, and delete have similar syntax\n",
    "#     print(r.text)\n",
    "\n",
    "#==============Main Preprocess Data and Import===============\n",
    "\n",
    "slice = 10\n",
    "names = os.listdir(folder_path)\n",
    "# before_import = 0\n",
    "failed_files = []\n",
    "for j in range(len(names)):\n",
    "    name = names[j]\n",
    "#     if os.path.splitext(name)[1] not in ['.doc','.docx']:continue\n",
    "    try:\n",
    "        df = read_doc(os.path.join(folder_path, name))\n",
    "        df = embbeding(df)\n",
    "        for i in range(len(df)//slice+1):\n",
    "            import_data(df[slice*i:slice*(i+1)], slice*i, before_import)\n",
    "            print('\\r import %i out of %i finished'%(i+1, len(df)//slice+1), end='')\n",
    "        before_import += len(df)\n",
    "        print(' file %i out of %i finished'%(j+1, len(names)//slice+1))\n",
    "    except Exception as ex:\n",
    "        # traceback.print_exc(file=sys.stdout)\n",
    "        failed_files.append(name)\n",
    "        print(f\"=================Exception================={ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff9dc43f-4291-4aa8-b4f1-0c02834ece24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>title_vector</th>\n",
       "      <th>sentence_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>\\n        &lt;!DOCTYPE html&gt;\\n        &lt;html lang=...</td>\n",
       "      <td>\\n        &lt;!DOCTYPE html&gt;\\n        &lt;html lang=...</td>\n",
       "      <td>[-1000, -1000, -1000, -1000, -1000, -1000, -10...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title                                          paragraph  \\\n",
       "0  test  \\n        <!DOCTYPE html>\\n        <html lang=...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  \\n        <!DOCTYPE html>\\n        <html lang=...   \n",
       "\n",
       "                                        title_vector sentence_vector  \n",
       "0  [-1000, -1000, -1000, -1000, -1000, -1000, -10...                  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "839ee97e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\n        <!DOCTYPE html>\\n        <html lang=\"en\">\\n        <head>\\n            <meta charset=\"UTF-8\">\\n            <title>pdf转换后的html文件</title>\\n        </head>\\n        <body>\\n        <div id=...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', None)\n",
    "\n",
    "# 设置 display.max_colwidth 为一个较大的值，这样 pandas 不会截断列\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "df.head(30).sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f8f8a-80e5-4e3a-8f23-ffbae6feb366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
