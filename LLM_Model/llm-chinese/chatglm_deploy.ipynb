{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c261e5f4-17a8-40da-beb9-599f1717e0fe",
   "metadata": {},
   "source": [
    "### 1. 安装HuggingFace 并下载模型到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02785614-9268-41c8-85a5-d579490edbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.175.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.28.9)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.24.3)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.5.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.9->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub -Uqq -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install -U sagemaker -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e6bd7ee-16a3-4f5a-8857-8bbba83eb9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./LLM_chatglm_model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"THUDM/chatglm-6b\"\n",
    "#commit_hash = \"f83182484538e663a03d3f73647f10f89878f438\"\n",
    "commit_hash=\"4d458d04bb657d100a3d2206a02c9f47c640e5c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94e8abc5-a58e-40e2-b1e6-fbf48307c716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d306d266cec846758ad47e8e8086a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 21 files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#执行这段，因为网络原因，可能会多次失败，需要反复执行\n",
    "while True:\n",
    "    try:\n",
    "        snapshot_download(repo_id=model_name, revision=commit_hash, cache_dir=local_model_path)\n",
    "        break\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d666c79-b039-4258-ac3b-46b19e63c3b8",
   "metadata": {},
   "source": [
    "### 2. 把模型拷贝到S3为后续部署做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9431deb-6359-442d-847b-1563f8dd3854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40dd8f16-ae7c-48bf-8e52-1a15425fa74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_code_prefix: LLM-RAG/workshop/LLM_chatglm_deploy_code\n",
      "model_snapshot_path: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = \"LLM-RAG/workshop/LLM_chatglm_model\"  # folder where model checkpoint will go\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_code_prefix = \"LLM-RAG/workshop/LLM_chatglm_deploy_code\"\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "067292c9-c066-4649-a61f-b460a24da584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.ipynb_checkpoints/configuration_chatglm-checkpoint.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.ipynb_checkpoints/configuration_chatglm-checkpoint.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.ipynb_checkpoints/README-checkpoint.md to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.ipynb_checkpoints/README-checkpoint.md\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.gitattributes to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.gitattributes\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.ipynb_checkpoints/modeling_chatglm-checkpoint.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.ipynb_checkpoints/modeling_chatglm-checkpoint.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/config.json to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/config.json\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.ipynb_checkpoints/tokenization_chatglm-checkpoint.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.ipynb_checkpoints/tokenization_chatglm-checkpoint.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/LICENSE to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/LICENSE\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.ipynb_checkpoints/quantization-checkpoint.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.ipynb_checkpoints/quantization-checkpoint.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/.ipynb_checkpoints/tokenizer_config-checkpoint.json to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/.ipynb_checkpoints/tokenizer_config-checkpoint.json\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/configuration_chatglm.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/configuration_chatglm.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/README.md to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/README.md\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/MODEL_LICENSE to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/MODEL_LICENSE\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/modeling_chatglm.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/modeling_chatglm.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/ice_text.model to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/ice_text.model\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00001-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00001-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00005-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00005-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00002-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00002-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model.bin.index.json to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model.bin.index.json\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/quantization.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/quantization.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00003-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00003-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00004-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00004-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/test_modeling_chatglm.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/test_modeling_chatglm.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/tokenization_chatglm.py to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/tokenization_chatglm.py\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/tokenizer_config.json to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/tokenizer_config.json\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00007-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00007-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00008-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00008-of-00008.bin\n",
      "upload: LLM_chatglm_model/models--THUDM--chatglm-6b/snapshots/4d458d04bb657d100a3d2206a02c9f47c640e5c5/pytorch_model-00006-of-00008.bin to s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/pytorch_model-00006-of-00008.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#上传模型至S3\n",
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b70c3-90f1-4175-95bf-568bafbcd383",
   "metadata": {},
   "source": [
    "### 3. 模型部署准备（entrypoint脚本，容器镜像，服务配置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f7c4277-4480-42c6-aee6-1fbcca94eb82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/djl-inference:0.22.1-deepspeed0.9.2-cu118\n"
     ]
    }
   ],
   "source": [
    "#适用于global\n",
    "#inference_image_uri = (\n",
    "#    f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.3-cu117\"\n",
    "#)\n",
    "\n",
    "#中国区需要替换为下面的image_uri\n",
    "inference_image_uri = (\n",
    "     #f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.21.0-deepspeed0.8.3-cu117\"\n",
    "    f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.22.1-deepspeed0.9.2-cu118\"\n",
    ")\n",
    "\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80413cea-82bb-49bb-bf4c-83e97657aa12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/djl-inference:0.23.0-deepspeed0.9.5-cu118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "\n",
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\",\n",
    "    region=sess.boto_session.region_name,\n",
    "    version=\"0.23.0\"\n",
    ")\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d771bdb-11d2-45d2-9bef-face29221838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p LLM_chatglm_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5348ecb-43df-4094-97d8-a6723004862a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LLM_chatglm_deploy_code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile LLM_chatglm_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "\n",
    "def load_model(properties):\n",
    "    logging.info(f\"properties: {properties}\")\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location, trust_remote_code=True)\n",
    "   \n",
    "    model = AutoModel.from_pretrained(model_location, trust_remote_code=True).half().cuda()\n",
    "    \n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "generator = None\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\")\n",
    "    return text\n",
    "\n",
    "def postprocess(text):\n",
    "    return text.replace(\"\\\\n\", \"\\n\").replace(\"\\\\t\", \"\\t\")\n",
    "\n",
    "def answer(text, history=[], sample=True, top_p=0.45, temperature=0.01, model=None):\n",
    "    text = preprocess(text)\n",
    "    response, history = model.chat(tokenizer, text, history=history, temperature=temperature)\n",
    "    \n",
    "    return postprocess(response), history\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer\n",
    "    if not model:\n",
    "        model, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    input_data = inputs.get_as_json()\n",
    "    logging.info(f\"inputs: {input_data}\")\n",
    "    try:\n",
    "        if 'history' not in input_data:\n",
    "            history = []\n",
    "        else:\n",
    "            history = input_data['history']\n",
    "        if 'temperature' not in input_data:\n",
    "            temperature = 0.01\n",
    "        else:\n",
    "            temperature = input_data['temperature']\n",
    "        response, history = answer(input_data['ask'], history=history, model=model)\n",
    "        logging.info(f'====result {response}====')\n",
    "        result = {\"answer\": response, \"history\" : history}\n",
    "        return Output().add_as_json(result)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        logging.error(f\"=================Exception================={ex}\")\n",
    "        \n",
    "    result = {\"answer\": \"No Answer\", \"history\" : history}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a863de32-910e-43f2-8206-68fba7d250c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option.s3url ==> s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"option.s3url ==> s3://{bucket}/{s3_model_prefix}/\")\n",
    "\n",
    "#使用打印出来的URL，替换下面一段代码中的S3Url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d1e60-3914-4059-a08f-05ac26761165",
   "metadata": {},
   "source": [
    "#### Note: option.s3url 需要按照自己的账号进行修改, 可以拷贝上一个cell的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8996fe44-8e70-468b-abc1-38187cb33f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LLM_chatglm_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile LLM_chatglm_deploy_code/serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.s3url = s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef22a2-27b9-4018-a46b-6a99b532512f",
   "metadata": {},
   "source": [
    "#### 注意: 必须把transformers升级到4.27.1以上，否则会出现 [Issue344](https://github.com/THUDM/ChatGLM-6B/issues/344)\n",
    "\n",
    "如果是中国区建议添加国内的pip镜像,如下代码所示\n",
    "```\n",
    "%%writefile LLM_chatglm_deploy_code/requirements.txt\n",
    "-i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "transformers==4.28.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b7e76c6-6dbc-47fc-9f47-4765c526ab76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LLM_chatglm_deploy_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile LLM_chatglm_deploy_code/requirements.txt\n",
    "-i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "transformers==4.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ae6734a-aacd-410d-818d-0a962697c3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_chatglm_deploy_code/\n",
      "LLM_chatglm_deploy_code/serving.properties\n",
      "LLM_chatglm_deploy_code/model.py\n",
      "LLM_chatglm_deploy_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz\n",
    "!cd LLM_chatglm_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz LLM_chatglm_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f77dc76-6d8c-4665-ba88-f03e887c136c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-cn-north-1-507392672631/LLM-RAG/workshop/LLM_chatglm_deploy_code/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5853daa-b8a3-4485-8c0a-64bf83e93a18",
   "metadata": {},
   "source": [
    "### 4. 创建模型 & 创建endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fbabeafc-8511-4190-81a6-6e8b4e41b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker delete-endpoint --endpoint-name pytorch-inference-llm-v1\n",
    "!aws sagemaker delete-endpoint-config --endpoint-config-name pytorch-inference-llm-v1\n",
    "!aws sagemaker delete-model --model-name pytorch-inference-llm-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ef974ca1-9638-45a8-9145-ea9d03b2b072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-inference-llm-v1\n",
      "Image going to be used is ---- > 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/djl-inference:0.23.0-deepspeed0.9.5-cu118\n",
      "Created Model: arn:aws-cn:sagemaker:cn-north-1:507392672631:model/pytorch-inference-llm-v1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = 'pytorch-inference-llm-v1'# name_from_base(f\"chatglm\") Note: Need to specify model_name\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "233bb3a4-d737-41ad-8fcc-7082c6278e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws-cn:sagemaker:cn-north-1:507392672631:endpoint-config/pytorch-inference-llm-v1',\n",
       " 'ResponseMetadata': {'RequestId': '5ac710ef-228f-49c2-95ef-1bdc23d43418',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5ac710ef-228f-49c2-95ef-1bdc23d43418',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '109',\n",
       "   'date': 'Wed, 09 Aug 2023 05:18:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_name =model_name # f\"{model_name}-config\"\n",
    "endpoint_name =model_name # f\"{model_name}-endpoint\"\n",
    "\n",
    "#Note: ml.g4dn.2xlarge 也可以选择\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "           # \"ContainerStartupHealthCheckTimeoutInSeconds\": 15*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "734a39b0-473e-4421-94c8-74d2b4105038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws-cn:sagemaker:cn-north-1:507392672631:endpoint/pytorch-inference-llm-v1\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262e826-a810-401d-a5a9-f62febb24e5f",
   "metadata": {},
   "source": [
    "#### 持续检测模型部署进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08969928-6b9e-4d9c-a033-a31f5f77bdfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985b427-3959-46f7-9a50-5a2b45e2d513",
   "metadata": {},
   "source": [
    "### 5. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56bfdaa-3469-4784-aa8a-e32177cde3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "sagemaker_endpoint_name='pytorch-inference-llm-v1'\n",
    "def query_endpoint_with_json_payload(encoded_json):\n",
    "    response = client.invoke_endpoint(EndpointName=sagemaker_endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    return response\n",
    "\n",
    "def parse_response_texts(query_response):\n",
    "    model_predictions = json.loads(query_response['Body'].read())\n",
    "    generated_text = model_predictions[\"answer\"]\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a1d32-d5d0-4b18-a5ac-063911f74498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\"ask\": \"\"\"已知信息:13英寸MacBook Pro。title: AI抢饭碗引发好莱坞大罢工！业内大佬警告：将产生多米诺骨牌效应\n",
    "ctime: 1689554822\n",
    "brief: ①前派拉蒙影业CEO巴里·迪勒表示，若不尽快解决好莱坞编剧和演员工会的罢工问题，将会带来毁灭性的影响；\n",
    "②当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。\n",
    "content: <p><strong>财联社7月17日讯（编辑 卞纯）</strong>人工智能（AI）对于美国好莱坞的冲击波仍在发酵。继美国编剧协会开始罢工以后，美国演员工会也加入了。</p>\n",
    "<p>当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。此前，工会方面与制片公司未能就劳资问题达成协议。。</第2条信息>\n",
    "<第3条信息>在人工智慧浪潮带动下，七家重量级科技股股价飙升40%至200%以上，成为标普500指数今年迄今17%的涨幅的主因，近期这几家公司更是被外界称为“绝地七骑士”，包括苹果、微软、谷歌、亚马逊、脸书、英伟达和特斯拉。</p>\n",
    "<p>  目前华尔街对七巨头的财报获利预期都相当高，美银全球研究预计，未来12个月，这些公司的收益将平均增长19%，是标普500指数其他成份股8%预期增幅的2倍多。</p>\n",
    "<p>在此背景下，特斯拉将于美东时间周三盘后（北京时间7月20日清晨）率先公布2023年二季度财报。值得关注的是，在最近一个月市场普遍预期Model 3将新增线控转向。</p>\n",
    "<p><strong>一、自动驾驶必备黑科技，各路资本纷纷入局</strong></p>\n",
    "<p>过去几年，智能汽车领域最热门的投资赛道，大多集中在智能驾驶的感知以及决策环节，比如激光雷达、毫米波雷达、AI芯片等。今年各路资本纷纷涌向线控底盘领域。。</第3条信息>\n",
    "<第5条信息>今日两市炸板个股较多，炸板率维持高位，目前超40%。短线情绪指标显示，市场短线情绪午后持续回落，接近低迷区。title: 金融学子就业高度内卷：卷学历、卷证书、卷实习，仍不敌复合人才\n",
    "ctime: 1689574264\n",
    "brief: ①2022年金融财经专业的应届生超过100万，占高校毕业生的10%；\n",
    "②人才饱和、竞争激烈将工作门槛无限拉高，金融学子们从各方面高度内卷；\n",
    "③现在，复合背景的金融人才往往更受券商青睐。\n",
    "content: <p><strong>财联社7月17日讯（记者 肖斐歆）</strong>金融专业曾是公认就业前景广、薪资水平高的行业，其中券商更是金融精英聚集地，是不少年轻人追逐的梦想工作去处。</p>\n",
    "<p>据教育部统计，2022年高校毕业生数量达1076万人，金融财经专业的应届生超过100万。不仅如此，学霸也偏爱金融专业，高考状元扎堆去顶级学府学金融似乎已是常态。</p>\n",
    "<p>门槛的无限拉高让金融学子们高度内卷，卷学历、卷证书、卷实习……伴随着券商降薪大潮的袭来和复合背景人才更受青睐的趋势，金融学子该何去何从？。</第5条信息>\n",
    "<第6条信息></p>title: 金梓才获擢升财通基金副总经理，绩而优则仕与80后标签打足，年内已近10位基金经理获提升\n",
    "ctime: 1689554818\n",
    "brief: ①金梓才的升任可以窥见财通基金的权益布局思路；\n",
    "②“绩优则仕”留人才，年内已有近10位基金经理升至副总。\n",
    "content: <p><strong>财联社7月17日讯（记者 闫军）</stro\n",
    "基于以上已知信息，简洁和专业的来回答用户的问题，并告知是依据哪些信息来进行回答的。\n",
    "如果无法从已知信息中得到答案，请仅回答 \"根据已知信息无法回答该问题\" 或 \"没有提供足够的相关信息\"，不允许在答案中添加编造成分，答案请使用中文。\n",
    "问题是:\n",
    "目前华尔街对七巨头期望怎么样？\"\"\"}\n",
    "query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "#print(query_response)\n",
    "#display_answer(query_response)\n",
    "generated_texts = parse_response_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaeb96b-54c4-4742-bb1c-d3fbdf14ddc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用 Markdown 格式打印模型输出\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "def display_answer(response_all):\n",
    "    for response, history in response_all:\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892eef81-919c-4f37-8142-ea3c7117624e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#chatglm1-6b g4dn.2xlarge\n",
    "payload = {\"ask\": \"\"\"\n",
    "人工智能（AI）对于美国好莱坞的冲击波仍在发酵。继美国编剧协会开始罢工以后，美国演员工会也加入了。</p>\n",
    "当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。此前，工会方面与制片公司未能就劳资问题达成协议。。</第2条信息>\n",
    "在人工智慧浪潮带动下，七家重量级科技股股价飙升40%至200%以上，成为标普500指数今年迄今17%的涨幅的主因，近期这几家公司更是被外界称为“绝地七骑士”，包括苹果、微软、谷歌、亚马逊、脸书、英伟达和特斯拉。</p>\n",
    "目前华尔街对七巨头的财报获利预期都相当高，美银全球研究预计，未来12个月，这些公司的收益将平均增长19%，是标普500指数其他成份股8%预期增幅的2倍多。</p>\n",
    "\n",
    "基于以上已知信息，简洁和专业的来回答用户的问题，并告知是依据哪些信息来进行回答的。\n",
    "如果无法从已知信息中得到答案，请仅回答 \"根据已知信息无法回答该问题\" 或 \"没有提供足够的相关信息\"，不允许在答案中添加编造成分，答案请使用中文。\n",
    "问题是:\n",
    "目前华尔街对七巨头期望怎么样？\"\"\"}\n",
    "query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "#print(query_response)\n",
    "#display_answer(query_response)\n",
    "generated_texts = parse_response_texts(query_response)\n",
    "\n",
    "display(Markdown(generated_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535e5e0-97f0-40ec-a91a-f0f1a356f65a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#chatglm-v1\n",
    "payload = {\"ask\": \"晚上睡不着怎么办？\"}\n",
    "query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "generated_texts = parse_response_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8b703-e312-4964-8be9-a754468e07cd",
   "metadata": {},
   "source": [
    "#### 清除模型Endpoint和config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906ad2f-e7db-499b-a976-a3e1f19ee3be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "sagemaker_endpoint_name='pytorch-inference-llm-v1'\n",
    "def cleanup():\n",
    "    # 创建一个sagemaker客户端\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "    # 删除模型\n",
    "    sagemaker.delete_model(ModelName=sagemaker_endpoint_name)\n",
    "\n",
    "    # 删除终端节点配置\n",
    "    sagemaker.delete_endpoint_config(EndpointConfigName=sagemaker_endpoint_name)\n",
    "\n",
    "    # 删除终端节点\n",
    "    sagemaker.delete_endpoint(EndpointName=sagemaker_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d116f-4fb1-4f04-8732-3d6e4fb520de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cleanup()\n",
    "#!aws sagemaker delete-endpoint --endpoint-name pytorch-inference-llm-v1\n",
    "#!aws sagemaker delete-endpoint-config --endpoint-config-name pytorch-inference-llm-v1\n",
    "#!aws sagemaker delete-model --model-name pytorch-inference-llm-v1"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
