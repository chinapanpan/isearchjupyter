{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f2c403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.28.7)\n",
      "Collecting boto3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/5e/a219cc9aa913a0e6f203c27e42eeb600d27e24cf9dd105daac8daaea01e5/boto3-1.28.9-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.6.0)\n",
      "Collecting botocore<1.32.0,>=1.31.9\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c1/5b/43d721ba00649b8d7c2d1002176a2f3bff556e5af61cd38858ef46e9300a/botocore-1.31.9-py3-none-any.whl (11.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.9->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.9->boto3) (1.26.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.9->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.7\n",
      "    Uninstalling botocore-1.31.7:\n",
      "      Successfully uninstalled botocore-1.31.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.7\n",
      "    Uninstalling boto3-1.28.7:\n",
      "      Successfully uninstalled boto3-1.28.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.71 requires botocore==1.29.71, but you have botocore 1.31.9 which is incompatible.\n",
      "awscli 1.27.71 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.28.9 botocore-1.31.9\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.173.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.22.3)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.6.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.5.2)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.28.9)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (65.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2022.7)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.9->boto3<2.0,>=1.26.131->sagemaker) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "!pip install --upgrade sagemaker -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4a30f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws-cn:iam::507392672631:role/NotebookStack-SmartSearchNotebookRole6F6BB12B-XOVHSG6091PM\n",
      "sagemaker-cn-north-1-507392672631\n",
      "dummy\n",
      "upload: ./model.tar.gz to s3://sagemaker-cn-north-1-507392672631/llm_chinese/assets/model.tar.gz\n",
      "----------------!"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)\n",
    "print(bucket)\n",
    "\n",
    "if \"cn-\" in region_name:\n",
    "    with open('./code/requirements.txt', 'r') as original: data = original.read()\n",
    "    with open('./code/requirements.txt', 'w') as modified: modified.write(\"-i https://pypi.tuna.tsinghua.edu.cn/simple\\n\" + data)\n",
    "\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "assets_dir = 's3://{0}/{1}/assets/'.format(bucket, 'llm_chinese')\n",
    "model_data = 's3://{0}/{1}/assets/model.tar.gz'.format(bucket, 'llm_chinese')\n",
    "!aws s3 cp model.tar.gz $assets_dir\n",
    "!rm -f dummy model.tar.gz\n",
    "\n",
    "model_name = None\n",
    "entry_point = 'inference.py'\n",
    "framework_version = '1.13.1'\n",
    "py_version = 'py39'\n",
    "model_environment = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT':'600', \n",
    "    'SAGEMAKER_MODEL_SERVER_WORKERS': '1', \n",
    "}\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    name = model_name,\n",
    "    model_data = model_data,\n",
    "    entry_point = entry_point,\n",
    "    source_dir = './code',\n",
    "    role = role,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    env = model_environment\n",
    ")\n",
    "\n",
    "endpoint_name = 'pytorch-inference-llm-v1'\n",
    "#instance_type = 'ml.p3.2xlarge'\n",
    "instance_type='ml.g4dn.2xlarge' \n",
    "\n",
    "instance_count = 1\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "predictor = model.deploy(\n",
    "    endpoint_name = endpoint_name,\n",
    "    instance_type = instance_type, \n",
    "    initial_instance_count = instance_count,\n",
    "    serializer = JSONSerializer(),\n",
    "    deserializer = JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f59e3f",
   "metadata": {},
   "source": [
    "### 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ada7d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#休眠2分钟,确保模型可以完全加载\n",
    "import time\n",
    "time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e48e6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from container model. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://cn-north-1.console.aws.amazon.com/cloudwatch/home?region=cn-north-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-inference-llm-v1 in account 507392672631 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m你好!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m inputs\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m晚上睡不着应该怎么办\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/base_predictor.py:167\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the inference from the specified endpoint.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m        as is.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m request_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_request_args(\n\u001b[1;32m    165\u001b[0m     data, initial_args, target_model, target_variant, inference_id\n\u001b[1;32m    166\u001b[0m )\n\u001b[0;32m--> 167\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from container model. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://cn-north-1.console.aws.amazon.com/cloudwatch/home?region=cn-north-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-inference-llm-v1 in account 507392672631 for more information."
     ]
    }
   ],
   "source": [
    "inputs= {\n",
    "    \"ask\": \"你好!\"\n",
    "\n",
    "}\n",
    "\n",
    "response = predictor.predict(inputs)\n",
    "print(response[\"answer\"])\n",
    "\n",
    "inputs= {\n",
    "    \"ask\": \"晚上睡不着应该怎么办\"\n",
    "\n",
    "}\n",
    "\n",
    "response = predictor.predict(inputs)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edc6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs= {\n",
    "    \"ask\": \"列出一些年夜饭好意头的菜肴以及其寓意!\"\n",
    "\n",
    "}\n",
    "\n",
    "response = predictor.predict(inputs)\n",
    "print(response[\"answer\"])\n",
    "\n",
    "inputs= {\n",
    "    \"ask\": \"帮我写一篇人工智能课程的教案，1000字\"\n",
    "\n",
    "}\n",
    "\n",
    "response = predictor.predict(inputs)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80082a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= {\n",
    "    \"ask\": \"怎么修改huggingface transformers的model cache位置\"\n",
    "\n",
    "}\n",
    "\n",
    "response = predictor.predict(inputs)\n",
    "print(response[\"answer\"])\n",
    "\n",
    "inputs= {\n",
    "    \"ask\": \"用python3写出快速排序代码\"\n",
    "\n",
    "}\n",
    "\n",
    "response = predictor.predict(inputs)\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ddf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们来查看一下刚部署的这个模型对应的SageMaker inference endpoint\n",
    "sagemaker_endpoint_name = predictor.endpoint_name\n",
    "sagemaker_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa257dda",
   "metadata": {},
   "source": [
    "利用已经在SageMaker real time inference endpoint部署的LLM模型来模拟单轮对话和多轮对话。\n",
    "\n",
    "下面的代码建议在SageMaker Notebook上来运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078035cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "sagemaker_endpoint_name='pytorch-inference-llm-v1'\n",
    "def query_endpoint_with_json_payload(encoded_json):\n",
    "    response = client.invoke_endpoint(EndpointName=sagemaker_endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    return response\n",
    "\n",
    "def parse_response_texts(query_response):\n",
    "    model_predictions = json.loads(query_response['Body'].read())\n",
    "    generated_text = model_predictions[\"answer\"]\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7922fd8",
   "metadata": {},
   "source": [
    "先简单测试一下针对单个问题的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c4f527-e9ab-4193-99e4-93acf7331113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据已知信息，华尔街对七巨头的财报获利预期都相当高。美银全球研究预计，未来12个月，这些公司的收益将平均增长19%，是标普500指数其他成份股8%预期增幅的2倍多。这反映出华尔街对七巨头的未来表现持乐观态度。\n"
     ]
    }
   ],
   "source": [
    "payload = {\"ask\": \"\"\"13英寸MacBook Pro。title: AI抢饭碗引发好莱坞大罢工！业内大佬警告：将产生多米诺骨牌效应\n",
    "ctime: 1689554822\n",
    "brief: ①前派拉蒙影业CEO巴里·迪勒表示，若不尽快解决好莱坞编剧和演员工会的罢工问题，将会带来毁灭性的影响；\n",
    "②当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。\n",
    "content: <p><strong>财联社7月17日讯（编辑 卞纯）</strong>人工智能（AI）对于美国好莱坞的冲击波仍在发酵。继美国编剧协会开始罢工以后，美国演员工会也加入了。</p>\n",
    "<p>当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。此前，工会方面与制片公司未能就劳资问题达成协议。。</第2条信息>\n",
    "<第3条信息>在人工智慧浪潮带动下，七家重量级科技股股价飙升40%至200%以上，成为标普500指数今年迄今17%的涨幅的主因，近期这几家公司更是被外界称为“绝地七骑士”，包括苹果、微软、谷歌、亚马逊、脸书、英伟达和特斯拉。</p>\n",
    "<p>  目前华尔街对七巨头的财报获利预期都相当高，美银全球研究预计，未来12个月，这些公司的收益将平均增长19%，是标普500指数其他成份股8%预期增幅的2倍多。</p>\n",
    "<p>在此背景下，特斯拉将于美东时间周三盘后（北京时间7月20日清晨）率先公布2023年二季度财报。值得关注的是，在最近一个月市场普遍预期Model 3将新增线控转向。</p>\n",
    "<p><strong>一、自动驾驶必备黑科技，各路资本纷纷入局</strong></p>\n",
    "<p>过去几年，智能汽车领域最热门的投资赛道，大多集中在智能驾驶的感知以及决策环节，比如激光雷达、毫米波雷达、AI芯片等。今年各路资本纷纷涌向线控底盘领域。。</第3条信息>\n",
    "<第5条信息>今日两市炸板个股较多，炸板率维持高位，目前超40%。短线情绪指标显示，市场短线情绪午后持续回落，接近低迷区。title: 金融学子就业高度内卷：卷学历、卷证书、卷实习，仍不敌复合人才\n",
    "ctime: 1689574264\n",
    "brief: ①2022年金融财经专业的应届生超过100万，占高校毕业生的10%；\n",
    "②人才饱和、竞争激烈将工作门槛无限拉高，金融学子们从各方面高度内卷；\n",
    "③现在，复合背景的金融人才往往更受券商青睐。\n",
    "content: <p><strong>财联社7月17日讯（记者 肖斐歆）</strong>金融专业曾是公认就业前景广、薪资水平高的行业，其中券商更是金融精英聚集地，是不少年轻人追逐的梦想工作去处。</p>\n",
    "<p>据教育部统计，2022年高校毕业生数量达1076万人，金融财经专业的应届生超过100万。不仅如此，学霸也偏爱金融专业，高考状元扎堆去顶级学府学金融似乎已是常态。</p>\n",
    "<p>门槛的无限拉高让金融学子们高度内卷，卷学历、卷证书、卷实习……伴随着券商降薪大潮的袭来和复合背景人才更受青睐的趋势，金融学子该何去何从？。</第5条信息>\n",
    "<第6条信息></p>title: 金梓才获擢升财通基金副总经理，绩而优则仕与80后标签打足，年内已近10位基金经理获提升\n",
    "ctime: 1689554818\n",
    "brief: ①金梓才的升任可以窥见财通基金的权益布局思路；\n",
    "②“绩优则仕”留人才，年内已有近10位基金经理升至副总。\n",
    "content: <p><strong>财联社7月17日讯（记者 闫军）</stro\n",
    "基于以上已知信息，简洁和专业的来回答用户的问题，并告知是依据哪些信息来进行回答的。\n",
    "如果无法从已知信息中得到答案，请仅回答 \"根据已知信息无法回答该问题\" 或 \"没有提供足够的相关信息\"，不允许在答案中添加编造成分，答案请使用中文。\n",
    "问题是:\n",
    "目前华尔街对七巨头期望怎么样？\"\"\"}\n",
    "query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "#print(query_response)\n",
    "#display_answer(query_response)\n",
    "generated_texts = parse_response_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd0dfa-481f-4526-8d06-acacbeb39736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\"ask\": \"\"\"已知信息:13英寸MacBook Pro。title: AI抢饭碗引发好莱坞大罢工！业内大佬警告：将产生多米诺骨牌效应\n",
    "ctime: 1689554822\n",
    "brief: ①前派拉蒙影业CEO巴里·迪勒表示，若不尽快解决好莱坞编剧和演员工会的罢工问题，将会带来毁灭性的影响；\n",
    "②当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。\n",
    "content: <p><strong>财联社7月17日讯（编辑 卞纯）</strong>人工智能（AI）对于美国好莱坞的冲击波仍在发酵。继美国编剧协会开始罢工以后，美国演员工会也加入了。</p>\n",
    "<p>当地时间14日，美国演员工会宣布支持美国编剧协会，正式加入罢工行列，这也是60多年来好莱坞最大的两个工会组织首次同时罢工。此前，工会方面与制片公司未能就劳资问题达成协议。。</第2条信息>\n",
    "<第3条信息>在人工智慧浪潮带动下，七家重量级科技股股价飙升40%至200%以上，成为标普500指数今年迄今17%的涨幅的主因，近期这几家公司更是被外界称为“绝地七骑士”，包括苹果、微软、谷歌、亚马逊、脸书、英伟达和特斯拉。</p>\n",
    "<p>  目前华尔街对七巨头的财报获利预期都相当高，美银全球研究预计，未来12个月，这些公司的收益将平均增长19%，是标普500指数其他成份股8%预期增幅的2倍多。</p>\n",
    "\n",
    "基于以上已知信息，简洁和专业的来回答用户的问题，并告知是依据哪些信息来进行回答的。\n",
    "如果无法从已知信息中得到答案，请仅回答 \"根据已知信息无法回答该问题\" 或 \"没有提供足够的相关信息\"，不允许在答案中添加编造成分，答案请使用中文。\n",
    "问题是:\n",
    "目前华尔街对七巨头期望怎么样？\"\"\"}\n",
    "query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "#print(query_response)\n",
    "#display_answer(query_response)\n",
    "generated_texts = parse_response_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"ask\": \"信息抽取：\\n2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\"}\n",
    "query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "generated_texts = parse_response_texts(query_response)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81504f9",
   "metadata": {},
   "source": [
    "单轮对话：每个问题/query都是独立的，问题之间没有关联性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82254c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.首先需要一个简单的开场拍。\n",
    "print(\"用户：你好！\\nAI：您好!我是AI。我可以回答您的问题、写文章、写作业、翻译，对于一些法律等领域的问题我也可以给你提供信息。\")\n",
    "\n",
    "#2.在同一个session中持续对话，但是每次对话之间没有什么关联。\n",
    "while True:\n",
    "    command = input(\"用户：\")\n",
    "    if command == 'quit':\n",
    "        break;\n",
    "    \n",
    "    #print(command)\n",
    "    payload = {\"ask\": \"\\n用户：\"+ command + \"\\n\"}\n",
    "    #print(payload[\"ask\"])\n",
    "    query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "    generated_texts = \"AI：\" + parse_response_texts(query_response)\n",
    "    print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326def35",
   "metadata": {},
   "source": [
    "多轮对话模拟：我们这里来测试一下多轮对话能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.首先需要开场拍来引导AI，其实就是给它一个上下文来启动所谓的对话session。\n",
    "payload = {\"ask\": \"用户：你好！\\nAI：您好!我是AI。我可以回答您的问题、写文章、写作业、翻译，对于一些法律等领域的问题我也可以给你提供信息。\"}\n",
    "print(payload[\"ask\"])\n",
    "generated_texts = \"\"\n",
    "\n",
    "#在这里简单模拟多轮对话时，发送给SageMaker endpoint的payload会越来越大，这里对payload大致做一个限制。\n",
    "session_len = 10 * 1024 * 1024 \n",
    "\n",
    "#2.在同一个session中持续对话，为了有多轮对话的效果，把每一轮的信息(问题-回答对)都带上来告诉LLM之前的上下文。\n",
    "while True:\n",
    "    command = input(\"用户：\")\n",
    "    if command == 'quit':\n",
    "        break;\n",
    "    \n",
    "    #print(command)\n",
    "    whole_context = payload[\"ask\"] + generated_texts + \"\\n用户：\"+ command + \"\\n\"\n",
    "    payload = {\"ask\": whole_context}\n",
    "    if len(whole_context) > session_len:\n",
    "        print(\"上下文信息太多了，当前对话session要退出了！\")\n",
    "        break;\n",
    "    #print(payload[\"ask\"])\n",
    "    query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "    generated_texts = \"AI：\" + parse_response_texts(query_response)\n",
    "    print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2dcc6a",
   "metadata": {},
   "source": [
    "### 删除SageMaker  Endpoint\n",
    "删除推理服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512b41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
